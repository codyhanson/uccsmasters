\section{Improvements and Further Work}

While I was able to successfully implement my goal of enabling client-side encryption, there are several aspects
of the program that could be improved. Some of the key areas for improvement include encryption key management,
data integrity features, S3 multi-part file uploads, and performance when encrypting very large amounts of data.
I will also briefly discuss integrating the feature into the Boto project.

\subsection{Key Management}
Encryption key management is currently a burden placed on the users. When a user creates an EncryptedKey object to store data in S3, they must pass in the string of their key. If they pass in the wrong key, and attempt to get file contents that was encrypted with a different key, their decryption will fail. A feature that would allow the user to determine which key they used would be helpful if the user is deploying more than one key.

A lightweight option would be to append the S3 Key name with a hint about the encryption key used. This could be used 
by a users program to lookup the correct encryption key before decrypting. 

\subsection{Data Integrity Checks}
My implementation does not currently include any authentication hashing which would indicate to a user that their data was tampered with.
Even though the data is encrypted, tampering can still occur. Depending on what data the user stores, they may not be able to tell that
the tampering occured.

A way to implement this could be signing the file with the users RSA key, or simply concatenating a hash of the plaintext to the file before it is sent to the cloud. Pycrypto provides many cryptographically strong hashing functions which would allow us to do this easily.

\subsection{Multi-part Upload Support}

The current maximum filesize for a single upload to S3 is 5 Gigabytes. Boto exposes S3 API's which allow users to do simple
single-part uploads, as well as multi-part uploads which support larger file sizes. A multi-part upload chunks very large 
files into manageable pieces, which are uploaded in parellel and then re-assembled on S3 once all parts have arrived.

The EncryptedKey class currently only protects single-part uploads. Adding mult-part encryption would be a good feature
to provide, but care should be taken to ensure that the file can be decrypted in the same chunked manner as it was
encrypted.

\subsection{Large File Performance}

In the current implementation, the entire file being encrypted is read into memory to be processed, before being handed off
to the Boto S3 core API. The reason for this was ease of implementation, and avoidance of modifying S3 file transfer code.
If a multi-gigabyte file is queued up to be transferred, performance of an average users machine would suffer as the file 
consumed much of the available memory, potentially causing a crash.

One potential fix for this problem is to encrypt the file in parts, and write them out back to disk. Then the encrypted file could be read from disk and incrementally sent by the S3 file transfer logic. This approach isn't ideal either, however, because it causes
increased disk accesses, which are also bad for performance. It also requires that the user have 2N bytes of disk 
space free for an N byte file. I think the ultimate resolution will be to possibly move the encryption step further into the core
of the library, or support some kind of file-sharding which will allow the encryption layer to remain at the top, but transfer chunks of the file incrementally.

\subsection{Incorporation into the Boto Project with Github}
As of the writing of this paper, I am working on getting my feature incorporated into the Boto mainline source tree. Once I 
get in contact with project maintainers I will be able to get feedback on my code, and work to improve and further test the
feature. Boto collaboration is done on Github, and the fork with my code can be found at \cite{CodyBoto} in the 'localencryption' branch.

I have used open-source technology for several years, but have never tried to contribute up till now. I find that Github and other tools like it do a marvelous job of
lowering the barrier to entry for people to contribute to projects. Truly anybody can follow development, see the code, and contribute a change, not just the elite members of some inner circle.


